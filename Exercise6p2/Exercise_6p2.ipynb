{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MUNgPo8DhVJ"
      },
      "source": [
        "# Exercise 6.2\n",
        "## Interpolation\n",
        "In this task, we implement a simple NN to learn a complicated function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jonSkW8HDhVN"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "layers = keras.layers\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB_BSlZGDhVP"
      },
      "source": [
        "### Generation of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dI2fNw7DhVP"
      },
      "source": [
        "def some_complicated_function(x):\n",
        "    return (\n",
        "        (np.abs(x)) ** 0.5\n",
        "        + 0.1 * x\n",
        "        + 0.01 * x ** 2\n",
        "        + 1\n",
        "        - np.sin(x)\n",
        "        + 0.5 * np.exp(x / 10.0)\n",
        "        ) / (0.5 + np.abs(np.cos(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx5vvoAwDhVQ"
      },
      "source": [
        "Let's simulate the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IeoimC8DhVQ"
      },
      "source": [
        "N_train = 10**4  # number of training samples\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "# Note: \"[:, np.newaxis]\" reshapes array to (N,1) as required by our DNN (we input one feature per sample)\n",
        "xtrain = rng.uniform(-10, 10, N_train)[:, np.newaxis]\n",
        "ytrain = some_complicated_function(xtrain) + rng.standard_normal(\n",
        "    xtrain.shape\n",
        ")  # train data includes some noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlI1OqbUDhVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237b6db3-ed2c-4f1e-eaef-ed2f3e449f27"
      },
      "source": [
        "print(f\"{xtrain.shape = }\")\n",
        "print(f\"{ytrain.shape = }\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xtrain.shape (10000, 1)\n",
            "ytrain.shape (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBU3EoJKDhVS"
      },
      "source": [
        "Simulate test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0bQ_GpYDhVS"
      },
      "source": [
        "N_test = 10000  # number of testing samples\n",
        "\n",
        "xtest = np.linspace(-10, 10, N_test)\n",
        "ytest = some_complicated_function(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEsr1VNzDhVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8cd3846-9000-450d-8dcf-794dc8f28913"
      },
      "source": [
        "print(f\"{xtest.shape = }\")\n",
        "print(f\"{ytest.shape = }\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xtest.shape (10000,)\n",
            "ytest.shape (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRRRNdKpDhVU"
      },
      "source": [
        "### Define Model\n",
        "\n",
        "Define the number of nodes, the number of layers, and choose an activation function.\n",
        "Use `keras.regularizers` to use parameter norm penalties or add a dropout layer via `layers.Dropout(fraction)`.\n",
        "\n",
        "You may use the skeleton below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v7d4JHZDhVU"
      },
      "source": [
        "nb_nodes = 1\n",
        "nb_layers = 1\n",
        "activation = \"\"\n",
        "\n",
        "model = keras.models.Sequential(name=\"1Dfit\")\n",
        "model.add(\n",
        "    layers.Dense(\n",
        "        nb_nodes,\n",
        "        activation=activation,\n",
        "        input_dim=xtrain.shape[1]\n",
        "    )\n",
        ")  # first layer\n",
        "\n",
        "model.add(layers.Dense(1))  # final layer\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zJykTHgDhVU"
      },
      "source": [
        "### Compile the model (set an objective and choose an optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1XQ_aPSDhVV"
      },
      "source": [
        "Choose an optimizer from `keras.optimizers`, e.g., `adam = keras.optimizers.Adam(learning_rate=0.001)`.\n",
        "\n",
        "Further, choose the correct objective (loss) for this <b>regression task</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rI_dLv7DhVV"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"\", optimizer=)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nnex8oJDhVV"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWd6kKyCDhVV"
      },
      "source": [
        "Train the network for a couple of epochs and save the model several times in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHhUTZLsDhVW"
      },
      "source": [
        "epochs =\n",
        "save_period =   # after how many epochs the model should be saved?\n",
        "\n",
        "chkpnt_saver = keras.callbacks.ModelCheckpoint(\n",
        "    \"weights-{epoch:02d}.weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=save_period\n",
        ")\n",
        "\n",
        "results = model.fit(\n",
        "    xtrain,\n",
        "    ytrain,\n",
        "    batch_size=64,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    callbacks=[chkpnt_saver]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON4FWth1DhVW"
      },
      "source": [
        "Compare the performance of the model during the training. You may use the skeleton below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT0EPJ0BDhVW"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12, 8))\n",
        "\n",
        "ax1.plot(xtest, ytest, color=\"#6495ED\", label=\"data\")\n",
        "saved_epochs = range(save_period, epochs + 1, save_period)\n",
        "\n",
        "colors = [\n",
        "    plt.cm.inferno((i + 1) / float(len(saved_epochs) + 1))\n",
        "    for i in range(len(saved_epochs))\n",
        "]\n",
        "\n",
        "for i, epoch in enumerate(saved_epochs):\n",
        "    model.load_weights(\"weights-{epoch:02d}.weights.h5\".format(epoch=epoch))\n",
        "    ypredict = model.predict(xtest).squeeze()\n",
        "    ax1.plot(xtest.squeeze(), ypredict, color=colors[i], label=epoch)\n",
        "    ax2.plot(\n",
        "        epoch,\n",
        "        results.history[\"loss\"][epoch - 1],\n",
        "        color=colors[i],\n",
        "        marker=\"o\",\n",
        "        zorder=10,\n",
        "    )\n",
        "\n",
        "ax1.set(xlabel=\"x\", ylabel=\"some_complicated_function(x)\", xlim=(-10, 13), title=\"\")\n",
        "ax1.grid(True)\n",
        "ax1.legend(loc=\"upper right\", title=\"Epochs\")\n",
        "\n",
        "ax2.plot(results.history[\"loss\"], color=\"#6495ED\")\n",
        "ax2.set(xlabel=\"epoch\", ylabel=\"loss\")\n",
        "ax2.grid(True)\n",
        "ax2.semilogy()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}