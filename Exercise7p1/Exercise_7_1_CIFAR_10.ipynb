{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIC4ypzrTXj7"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "layers = tf.keras.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdB6l-5s-7cJ"
      },
      "source": [
        "The code block below defines a few helper functions to visualize the results. You do not need to touch them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCxC5DPEkGLn"
      },
      "source": [
        "def plot_examples(X, Y, n=10):\n",
        "    \"\"\" Plot the first n examples for each of the 10 classes in the CIFAR dataset X, Y \"\"\"\n",
        "    fig, axes = plt.subplots(n, 10, figsize=(10, n))\n",
        "    for l in range(10):\n",
        "        axes[0, l].set_title(cifar10_labels[l], fontsize=\"smaller\")\n",
        "        m = np.squeeze(Y) == l  # boolean mask: True for all images of label l\n",
        "        for i in range(n):\n",
        "            image = X[m][i].astype(\"uint8\")  # imshow expects uint8\n",
        "            ax = axes[i, l]\n",
        "            ax.imshow(image, origin=\"upper\")\n",
        "            ax.set(xticks=[], yticks=[])\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def plot_prediction(X, Y, Y_predict):\n",
        "    \"\"\"\n",
        "    Plot image X along with predicted probabilities Y_predict.\n",
        "    X: CIFAR image, shape = (32, 32, 3)\n",
        "    Y: CIFAR label, one-hot encoded, shape = (10)\n",
        "    Y_predict: predicted probabilities, shape = (10)\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    # plot image\n",
        "    ax1.imshow(X.astype(\"uint8\"), origin=\"upper\")\n",
        "    ax1.set(xticks=[], yticks=[])\n",
        "\n",
        "    # plot probabilities\n",
        "    ax2.barh(np.arange(10), Y_predict, align=\"center\")\n",
        "    ax2.set(xlim=(0, 1), xlabel=\"Score\", yticks=[])\n",
        "    for i in range(10):\n",
        "        c = \"red\" if (i == np.argmax(Y)) else \"black\"\n",
        "        ax2.text(0.05, i, cifar10_labels[i].capitalize(), ha=\"left\", va=\"center\", color=c)\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion(Y_true, Y_predict):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "    Y_true:    array of true classifications (0-9), shape = (N)\n",
        "    Y_predict: array of predicted classifications (0-9), shape = (N)\n",
        "    \"\"\"\n",
        "    C = np.histogram2d(Y_true, Y_predict, bins=np.linspace(-0.5, 9.5, 11))[0]\n",
        "    Cn = C / np.sum(C, axis=1)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(Cn, interpolation=\"nearest\", vmin=0, vmax=1, cmap=plt.cm.YlGnBu)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"prediction\")\n",
        "    plt.ylabel(\"truth\")\n",
        "    plt.xticks(range(10), cifar10_labels, rotation=\"vertical\")\n",
        "    plt.yticks(range(10), cifar10_labels)\n",
        "    for x in range(10):\n",
        "        for y in range(10):\n",
        "            plt.annotate(\"%i\" % C[x, y], xy=(y, x), ha=\"center\", va=\"center\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_hToNncTkT0"
      },
      "source": [
        "First we load and preprocess CIFAR-10 data. The imagages are 32x32 pixels and have three color channels (red, green blue)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0tpFVjwTklD",
        "outputId": "4b4710c5-851b-437d-a8aa-575c2cf12f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# X: images, Y: labels\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(\"images, shape = \", x_train.shape)\n",
        "print(\"labels, shape = \", y_train.shape)\n",
        "\n",
        "cifar10_labels = np.array([\n",
        "    'airplane',\n",
        "    'automobile',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images, shape =  (50000, 32, 32, 3)\n",
            "labels, shape =  (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsrAdqcbBaMS"
      },
      "source": [
        "# Hint: To plot example images, you can use the plot examples function\n",
        "# plot_examples(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzsaCtB_ZQpn"
      },
      "source": [
        "# convert labels (\"0\"-\"9\") to one-hot encodings, \"0\" = (1, 0, ... 0) and so on\n",
        "y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)[:8000]\n",
        "y_valid_onehot = tf.keras.utils.to_categorical(y_test, 10)[8000:]\n",
        "\n",
        "# Hint: normalize the data\n",
        "# Hint: use 20% of the training data for validation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK4hJmraZX9k"
      },
      "source": [
        "We start with a fully connected network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6fLIMDOZaSp",
        "outputId": "da6cb119-afde-4a54-f8fd-991ad1230b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Define model\n",
        "# ----------------------------------------------------------\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        layers.Flatten(input_shape=(32, 32, 3)),  # (32,32,3) --> (3072)\n",
        "        # this time the flatten operation is directly integrated into the network\n",
        "        # structure so that we can use the same input data later for a convolutional neural network.\n",
        "        ...\n",
        "        # Hint: remember that the output layer should have 10 nodes with a softmax activation\n",
        "    ],\n",
        "    name=\"nn\",\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Only instances of `keras.Layer` can be added to a Sequential model. Received: Ellipsis (of type <class 'ellipsis'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-97d31b1e0b83>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ----------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model = tf.keras.models.Sequential(\n\u001b[0m\u001b[1;32m      5\u001b[0m     [\n\u001b[1;32m      6\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# (32,32,3) --> (3072)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;34m\"Only instances of `keras.Layer` can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"added to a Sequential model. Received: {layer} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: Ellipsis (of type <class 'ellipsis'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxFRmIDuZjA8"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Training\n",
        "# ----------------------------------------------------------\n",
        "model.compile(\n",
        "    ...\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ...\n",
        "    batch_size=...,\n",
        "    epochs=20, # train at least for 20 epochs\n",
        "    verbose=2,\n",
        "    validation_data=(x_valid_norm, y_valid_onehot),\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger(\"history_{}.csv\".format(model.name))],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKDrWN9nZqIP"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Plots\n",
        "# ----------------------------------------------------------\n",
        "# training curves\n",
        "history = np.genfromtxt(\"history_{}.csv\".format(model.name), delimiter=\",\", names=True)\n",
        "\n",
        "\n",
        "# Hint: this is how you can plot the confusion matrix.\n",
        "# calculate predictions for test set\n",
        "y_predict = model.predict(..., batch_size=128)\n",
        "\n",
        "# convert back to class labels (0-9)\n",
        "y_predict_cl = np.argmax(y_predict, axis=1)\n",
        "y_test_cl = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# plot confusion matrix\n",
        "plot_confusion(y_test_cl, y_predict_cl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HF58Clib-ZL"
      },
      "source": [
        "# Task: plot a few examples of correctly and incorrectly classified images.\n",
        "# Hint: First find the indices of correctly and incorrectly classified images:\n",
        "m = y_predict_cl == y_test_cl\n",
        "i0 = np.arange(8000)[~m]  # misclassified images\n",
        "i1 = np.arange(8000)[m]  # correctly classified images\n",
        "\n",
        "# original (unnormalized) test images\n",
        "x_test = x_test[:8000]\n",
        "\n",
        "# Hint: Now you can use the `plot_prediction` function to plot the images:\n",
        "# plot first 10 false classifications\n",
        "for i in i0[0:10]:\n",
        "    plot_prediction(x_test[i], y_test_onehot[i], y_predict[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfxphxaYaB1E"
      },
      "source": [
        "**CNN**\n",
        "In the second part of this exercise, classify the images with a CNN.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmApnvXvVdLZ"
      },
      "source": [
        "# Hint: this code snipped shows how to define convolution and maxpooling layers. For more information see\n",
        "# https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "# https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        ... # add additional convolution layer and max pooling layer here,\n",
        "        layers.Flatten(),\n",
        "        ... # add dropout and output layer\n",
        "    ],\n",
        "    name=\"cnn\",\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogdq9XKDVlxw"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Training\n",
        "# ----------------------------------------------------------\n",
        "model.compile(\n",
        "...\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ...\n",
        "    batch_size=..,\n",
        "    epochs=40,\n",
        "    validation_data=(x_valid_norm, y_valid_onehot),\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger(\"history_{}.csv\".format(model.name))],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}